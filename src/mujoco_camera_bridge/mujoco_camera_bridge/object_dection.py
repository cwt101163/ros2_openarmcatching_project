import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image  # åªä¿ç•™Imageå¯¼å…¥
from geometry_msgs.msg import PointStamped
import cv2
import numpy as np
from cv_bridge import CvBridge
import json
from tf2_ros import TransformListener, Buffer
import sys


# ========== ç‰©ä½“æ£€æµ‹æ ¸å¿ƒèŠ‚ç‚¹ï¼ˆæ— Open3Dï¼Œæ— å†…å­˜é—®é¢˜ï¼‰ ==========
class ObjectDetectionNode(Node):
    def __init__(self):
        super().__init__("object_detection_node")
        self.bridge = CvBridge()
        # TF2åæ ‡è½¬æ¢ï¼ˆä¿ç•™åŸåŠŸèƒ½ï¼‰
        self.tf_buffer = Buffer()
        self.tf_listener = TransformListener(self.tf_buffer, self)

        # è®¢é˜…å™¨ï¼šç›´æ¥è®¢é˜…ç›¸æœºåŸå§‹æ¶ˆæ¯
        self.rgb_sub = self.create_subscription(Image, "/camera/image_raw", self.rgb_callback, 10)
        self.depth_sub = self.create_subscription(Image, "/camera/depth/image_raw", self.depth_callback, 10)

        # å‘å¸ƒå™¨ï¼šä»…ä¿ç•™åŸºåæ ‡ç³»ç‰©ä½“åæ ‡
        self.object_pub = self.create_publisher(PointStamped, "/object/base/position", 10)

        # ç¼“å­˜RGBå’Œæ·±åº¦å›¾
        self.rgb_img = None
        self.depth_img = None
        # ç›¸æœºå†…å‚ï¼ˆé€‚é…320x240åˆ†è¾¨ç‡ï¼‰
        self.camera_matrix = np.array([[200, 0, 160],  # fx=200, cx=160
                                       [0, 200, 120],  # fy=200, cy=120
                                       [0, 0, 1]], dtype=np.float32)

        # åŠ è½½æ‰‹çœ¼æ ‡å®šç»“æœ
        self.calib_R, self.calib_t = self.load_calibration_result()
        self.get_logger().info("âœ… ç‰©ä½“æ£€æµ‹èŠ‚ç‚¹å·²å¯åŠ¨ï¼ˆæ— Open3Dç‰ˆæœ¬ï¼‰")

        # åˆå§‹åŒ–æ˜¾ç¤ºçª—å£
        cv2.namedWindow("Object Detection", cv2.WINDOW_NORMAL)
        cv2.resizeWindow("Object Detection", 640, 480)

    def load_calibration_result(self):
        calib_path = "/home/breeze/ros2_ws/src/openarm_moveit_config/config/handeye_data/calibration_result.json"
        try:
            with open(calib_path, "r") as f:
                data = json.load(f)
            R = np.array(data["rotation"], dtype=np.float32)
            t = np.array(data["translation"], dtype=np.float32).reshape(3, 1)
            self.get_logger().info("âœ… æ‰‹çœ¼æ ‡å®šç»“æœåŠ è½½æˆåŠŸ")
            return R, t
        except Exception as e:
            self.get_logger().warn(f"âš ï¸ æ ‡å®šæ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œç”¨é»˜è®¤å€¼ï¼š{str(e)}")
            return np.eye(3, dtype=np.float32), np.array([[0.3], [0.0], [0.8]], dtype=np.float32)

    def rgb_callback(self, msg):
        try:
            self.rgb_img = self.bridge.imgmsg_to_cv2(msg, desired_encoding="bgr8")
        except Exception as e:
            self.get_logger().error(f"âŒ RGBè½¬æ¢å¤±è´¥ï¼š{str(e)}")

    def depth_callback(self, msg):
        if self.rgb_img is None:
            return

        try:
            # 1. è½¬æ¢æ·±åº¦å›¾ï¼ˆ16UC1â†’ç±³ï¼‰
            self.depth_img = self.bridge.imgmsg_to_cv2(msg, desired_encoding="16UC1")
            depth_m = self.depth_img.astype(np.float32) / 1000.0
            depth_m[depth_m == 0] = -1

            # 2. é¢œè‰²è¯†åˆ«
            hsv = cv2.cvtColor(self.rgb_img, cv2.COLOR_BGR2HSV)
            lower_yellow = np.array([5, 30, 30])
            upper_yellow = np.array([45, 255, 255])
            mask = cv2.inRange(hsv, lower_yellow, upper_yellow)

            # 3. æ‰¾é»„è‰²åŒºåŸŸè´¨å¿ƒ
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if not contours:
                self.get_logger().warn("âš ï¸ æœªæ£€æµ‹åˆ°é»„è‰²ç‰©ä½“")
                cv2.imshow("Object Detection", self.rgb_img)
                cv2.waitKey(1)
                return

            max_contour = max(contours, key=cv2.contourArea)
            M = cv2.moments(max_contour)
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])

            # 4. å¯è§†åŒ–
            vis_img = self.rgb_img.copy()
            cv2.drawContours(vis_img, [max_contour], -1, (0, 255, 0), 2)
            cv2.circle(vis_img, (cx, cy), 5, (0, 0, 255), -1)
            cv2.imshow("Object Detection", vis_img)
            cv2.waitKey(1)

            # 5. è®¡ç®—3Dåæ ‡ï¼ˆç›¸æœºåæ ‡ç³»ï¼‰
            if depth_m[cy, cx] == -1:
                self.get_logger().warn("âš ï¸ è´¨å¿ƒå¤„æ·±åº¦æ— æ•ˆ")
                return
            u, v = cx, cy
            z = depth_m[cy, cx]
            x = (u - self.camera_matrix[0, 2]) * z / self.camera_matrix[0, 0]
            y = (v - self.camera_matrix[1, 2]) * z / self.camera_matrix[1, 1]
            cam_point = np.array([[x], [y], [z]], dtype=np.float32)

            # 6. åæ ‡è½¬æ¢ï¼ˆç›¸æœºâ†’åŸºåæ ‡ç³»ï¼‰
            base_point = self.calib_R @ cam_point + self.calib_t

            # 7. å‘å¸ƒç»“æœï¼ˆæ˜¾å¼è½¬ä¸ºfloatï¼‰
            object_msg = PointStamped()
            object_msg.header.frame_id = "base_link"
            object_msg.header.stamp = self.get_clock().now().to_msg()
            object_msg.point.x = float(base_point[0, 0])
            object_msg.point.y = float(base_point[1, 0])
            object_msg.point.z = float(base_point[2, 0])
            self.object_pub.publish(object_msg)

            # æ‰“å°æ—¥å¿—
            self.get_logger().info(
                f"ğŸ“· ç›¸æœºåæ ‡ï¼šX={x:.3f}, Y={y:.3f}, Z={z:.3f} | ğŸ¤– åŸºåæ ‡ï¼šX={base_point[0, 0]:.3f}, Y={base_point[1, 0]:.3f}, Z={base_point[2, 0]:.3f}")

        except Exception as e:
            self.get_logger().error(f"âŒ æ£€æµ‹å¤±è´¥ï¼š{str(e)}ï¼Œè¡Œå·ï¼š{sys.exc_info()[2].tb_lineno}")


def main(args=None):
    rclpy.init(args=args)
    node = ObjectDetectionNode()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        node.get_logger().info("ğŸ›‘ èŠ‚ç‚¹ç»ˆæ­¢")
    finally:
        cv2.destroyAllWindows()
        node.destroy_node()
        rclpy.shutdown()


if __name__ == "__main__":
    main()